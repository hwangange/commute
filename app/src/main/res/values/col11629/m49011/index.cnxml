<?xml version="1.0"?>
<document xmlns="http://cnx.rice.edu/cnxml" xmlns:md="http://cnx.rice.edu/mdml" xmlns:bib="http://bibtexml.sf.net/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:q="http://cnx.rice.edu/qml/1.0" id="new" cnxml-version="0.7" module-id="new">

<title>Analyzing Findings</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml"
          mdml-version="0.5">
  <!-- WARNING! The 'metadata' section is read only. Do not edit below.
       Changes to the metadata section in the source will not be saved. -->
  <md:repository>https://legacy.cnx.org/content</md:repository>
  <md:content-url>https://legacy.cnx.org/content/m49011/latest/</md:content-url>
  <md:content-id>m49011</md:content-id>
  <md:title>Analyzing Findings</md:title>
  <md:version>1.10</md:version>
  <md:created>2014/02/07 03:38:43 -0600</md:created>
  <md:revised>2018/02/28 11:41:32.564 US/Central</md:revised>
  <md:actors>
    <md:organization userid="OpenStaxCollege">
      <md:shortname>OpenStax</md:shortname>
      <md:fullname>OpenStax</md:fullname>
      <md:email>info@openstax.org</md:email>
    </md:organization>
    <md:person userid="OSCRiceUniversity">
      <md:firstname>Rice</md:firstname>
      <md:surname>University</md:surname>
      <md:fullname>Rice University</md:fullname>
      <md:email>info@openstaxcollege.org</md:email>
    </md:person>
    <md:person userid="cnxpsych">
      <md:firstname>CNX</md:firstname>
      <md:surname>Psychology</md:surname>
      <md:fullname>OpenStax Psychology</md:fullname>
      <md:email>info@openstaxcollege.org</md:email>
    </md:person>
  </md:actors>
  <md:roles>
    <md:role type="author">OpenStaxCollege</md:role>
    <md:role type="maintainer">OpenStaxCollege cnxpsych</md:role>
    <md:role type="licensor">OSCRiceUniversity</md:role>
  </md:roles>
  <md:license url="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License 4.0</md:license>
  <!-- For information on license requirements for use or modification, see license url in the
       above <md:license> element.
       For information on formatting required attribution, see the URL:
         CONTENT_URL/content_info#cnx_cite_header
       where CONTENT_URL is the value provided above in the <md:content-url> element.
  -->
  <md:keywordlist>
    <md:keyword>causality</md:keyword>
    <md:keyword>cause and effect</md:keyword>
    <md:keyword>cause-and-effect relationship</md:keyword>
    <md:keyword>confirmation bias</md:keyword>
    <md:keyword>confounding variable</md:keyword>
    <md:keyword>control group</md:keyword>
    <md:keyword>correlation</md:keyword>
    <md:keyword>correlational research</md:keyword>
    <md:keyword>correlation coefficient</md:keyword>
    <md:keyword>dependent variable</md:keyword>
    <md:keyword>double-blind study</md:keyword>
    <md:keyword>experimental group</md:keyword>
    <md:keyword>experimenter bias</md:keyword>
    <md:keyword>false correlation</md:keyword>
    <md:keyword>hypothesis</md:keyword>
    <md:keyword>illusory correlation</md:keyword>
    <md:keyword>independent variable</md:keyword>
    <md:keyword>negative correlation</md:keyword>
    <md:keyword>operational definition</md:keyword>
    <md:keyword>participant</md:keyword>
    <md:keyword>peer-reviewed journal article</md:keyword>
    <md:keyword>positive correlation</md:keyword>
    <md:keyword>random assignment</md:keyword>
    <md:keyword>random sample</md:keyword>
    <md:keyword>reliability</md:keyword>
    <md:keyword>replication</md:keyword>
    <md:keyword>single-blind study</md:keyword>
    <md:keyword>statistical analysis</md:keyword>
    <md:keyword>validity</md:keyword>
    <md:keyword>variable</md:keyword>
  </md:keywordlist>
  <md:subjectlist>
    <md:subject>Social Sciences</md:subject>
  </md:subjectlist>
  <md:abstract>By the end of this section, you will be able to:
<list>
<item>Explain what a correlation coefficient tells us about the relationship between variables</item>
<item>Recognize that correlation does not indicate a cause-and-effect relationship between variables</item>
<item>Discuss our tendency to look for relationships between variables that do not really exist</item>
<item>Explain random sampling and assignment of participants into experimental and control groups</item>
<item>Discuss how experimenter or participant bias could affect the results of an experiment</item>
<item>Identify independent and dependent variables</item>
</list></md:abstract>
  <md:language>en</md:language>
  <!-- WARNING! The 'metadata' section is read only. Do not edit above.
       Changes to the metadata section in the source will not be saved. -->
</metadata>

<content>
<para id="fs-idm9597360">Did you know that as sales in ice cream increase, so does the overall rate of crime? Is it possible that indulging in your favorite flavor of ice cream could send you on a crime spree? Or, after committing crime do you think you might decide to treat yourself to a cone? There is no question that a relationship exists between ice cream and crime (e.g., Harper, 2013), but it would be pretty foolish to decide that one thing actually caused the other to occur.</para>
<para id="fs-idm8747152">It is much more likely that both ice cream sales and crime rates are related to the temperature outside. When the temperature is warm, there are lots of people out of their houses, interacting with each other, getting annoyed with one another, and sometimes committing crimes. Also, when it is warm outside, we are more likely to seek a cool treat like ice cream. How do we determine if there is indeed a relationship between two things? And when there is a relationship, how can we discern whether it is attributable to coincidence or causation?</para>

<section id="fs-idm28272816">
<title>CORRELATIONAL RESEARCH</title>
<para id="fs-idm37916512"><term>Correlation</term> means that there is a relationship between two or more variables (such as ice cream consumption and crime), but this relationship does not necessarily imply cause and effect. When two variables are correlated, it simply means that as one variable changes, so does the other. We can measure correlation by calculating a statistic known as a correlation coefficient. A <term>correlation coefficient</term> is a number from -1 to +1 that indicates the strength and direction of the relationship between variables. The correlation coefficient is usually represented by the letter <emphasis effect="italics">r</emphasis>.</para>
<para id="fs-idp46664736">The number portion of the correlation coefficient indicates the strength of the relationship. The closer the number is to 1 (be it negative or positive), the more strongly related the variables are, and the more predictable changes in one variable will be as the other variable changes. The closer the number is to zero, the weaker the relationship, and the less predictable the relationships between the variables becomes. For instance, a correlation coefficient of 0.9 indicates a far stronger relationship than a correlation coefficient of 0.3. If the variables are not related to one another at all, the correlation coefficient is 0. The example above about ice cream and crime is an example of two variables that we might expect to have no relationship to each other.</para>
<para id="fs-idm10144032">The sign—positive or negative—of the correlation coefficient indicates the direction of the relationship (<link target-id="CNX_Psych_02_04_scatter"/>). A <term>positive correlation</term> means that the variables move in the same direction. Put another way, it means that as one variable increases so does the other, and conversely, when one variable decreases so does the other. A <term>negative correlation</term> means that the variables move in opposite directions. If two variables are negatively correlated, a decrease in one variable is associated with an increase in the other and vice versa.</para>
<para id="fs-idm12626416">The example of ice cream and crime rates is a positive correlation because both variables increase when temperatures are warmer. Other examples of positive correlations are the relationship between an individual’s height and weight or the relationship between a person’s age and number of wrinkles. One might expect a negative correlation to exist between someone’s tiredness during the day and the number of hours they slept the previous night: the amount of sleep decreases as the feelings of tiredness increase. In a real-world example of negative correlation, student researchers at the University of Minnesota found a weak negative correlation (<emphasis effect="italics">r</emphasis> = -0.29) between the average number of days per week that students got fewer than 5 hours of sleep and their GPA (Lowry, Dean, &amp; Manders, 2010). Keep in mind that a negative correlation is not the same as no correlation. For example, we would probably find no correlation between hours of sleep and shoe size.</para>
<para id="fs-idm4271152">As mentioned earlier, correlations have predictive value. Imagine that you are on the admissions committee of a major university. You are faced with a huge number of applications, but you are able to accommodate only a small percentage of the applicant pool. How might you decide who should be admitted? You might try to correlate your current students’ college GPA with their scores on standardized tests like the SAT or ACT. By observing which correlations were strongest for your current students, you could use this information to predict relative success of those students who have applied for admission into the university.</para>

<figure id="CNX_Psych_02_04_scatter">
<media id="fs-idp4163728" alt="Three scatterplots are shown. Scatterplot (a) is labeled &#x201C;positive correlation&#x201D; and shows scattered dots forming a rough line from the bottom left to the top right; the x-axis is labeled &#x201C;weight&#x201D; and the y-axis is labeled &#x201C;height.&#x201D; Scatterplot (b) is labeled &#x201C;negative correlation&#x201D; and shows scattered dots forming a rough line from the top left to the bottom right; the x-axis is labeled &#x201C;tiredness&#x201D; and the y-axis is labeled &#x201C;hours of sleep.&#x201D; Scatterplot (c) is labeled &#x201C;no correlation&#x201D; and shows scattered dots having no pattern; the x-axis is labeled &#x201C;shoe size&#x201D; and the y-axis is labeled &#x201C;hours of sleep.&#x201D;">
<image mime-type="image/jpeg" src="CNX_Psych_02_04_scatter.jpg"/>
</media>
<caption>Scatterplots are a graphical view of the strength and direction of correlations. The stronger the correlation, the closer the data points are to a straight line. In these examples, we see that there is (a) a positive correlation between weight and height, (b) a negative correlation between tiredness and hours of sleep, and (c) no correlation between shoe size and hours of sleep.</caption>
</figure>

<note id="fs-idm30960032" class="psychology link-to-learning"><label>Link to Learning</label>

<media id="fs-idm50964608" alt=" ">
<image mime-type="png" src="OSC_Interactive_150.png"/>
</media>

<para id="fs-idm12416800">Manipulate this <link url="http://openstaxcollege.org/l/scatplot">interactive scatterplot</link> to practice your understanding of positive and negative correlation.</para>
</note><section id="fs-idm84043200">
<title>Correlation Does Not Indicate Causation </title>
<para id="fs-idp46775888">Correlational research is useful because it allows us to discover the strength and direction of relationships that exist between two variables. However, correlation is limited because establishing the existence of a relationship tells us little about <term>cause and effect</term>. While variables are sometimes correlated because one does cause the other, it could also be that some other factor, a <term>confounding variable</term>, is actually causing the systematic movement in our variables of interest. In the ice cream/crime rate example mentioned earlier, temperature is a confounding variable that could account for the relationship between the two variables.</para>
<para id="fs-idm12088928">Even when we cannot point to clear confounding variables, we should not assume that a correlation between two variables implies that one variable causes changes in another. This can be frustrating when a cause-and-effect relationship seems clear and intuitive. Think back to our discussion of the research done by the American Cancer Society and how their research projects were some of the first demonstrations of the link between smoking and cancer. It seems reasonable to assume that smoking causes cancer, but if we were limited to <term class="no-emphasis">correlational research</term>, we would be overstepping our bounds by making this assumption.</para>
<para id="fs-idm37888912">Unfortunately, people mistakenly make claims of causation as a function of correlations all the time. Such claims are especially common in advertisements and news stories. For example, recent research found that people who eat cereal on a regular basis achieve healthier weights than those who rarely eat cereal (Frantzen, Treviño, Echon, Garcia-Dominic, &amp; DiMarco, 2013; Barton et al., 2005). Guess how the cereal companies report this finding. Does eating cereal really cause an individual to maintain a healthy weight, or are there other possible explanations, such as, someone at a healthy weight is more likely to regularly eat a healthy breakfast than someone who is obese or someone who avoids meals in an attempt to diet (<link target-id="CNX_Psych_02_04_cereal"/>)? While correlational research is invaluable in identifying relationships among variables, a major limitation is the inability to establish causality. Psychologists want to make statements about cause and effect, but the only way to do that is to conduct an experiment to answer a research question. The next section describes how scientific experiments incorporate methods that eliminate, or control for, alternative explanations, which allow researchers to explore how changes in one variable cause changes in another variable.</para>

<figure id="CNX_Psych_02_04_cereal">
<media id="fs-idm23474448" alt="A photograph shows a bowl of cereal.">
<image mime-type="image/jpeg" src="CNX_Psych_02_04_cereal.jpg"/>
</media>
<caption>Does eating cereal really cause someone to be a healthy weight? (credit: Tim Skillern)</caption>
</figure>
</section>
<section id="fs-idm54837568">
<title>Illusory Correlations </title>
<para id="fs-idp9589232">The temptation to make erroneous cause-and-effect statements based on correlational research is not the only way we tend to misinterpret data. We also tend to make the mistake of illusory correlations, especially with unsystematic observations. <term>Illusory correlations</term>, or false correlations, occur when people believe that relationships exist between two things when no such relationship exists. One well-known illusory correlation is the supposed effect that the moon’s phases have on human behavior. Many people passionately assert that human behavior is affected by the phase of the moon, and specifically, that people act strangely when the moon is full (<link target-id="CNX_Psych_02_04_moon"/>).</para>

<figure id="CNX_Psych_02_04_moon">
<media id="fs-idm6412208" alt="A photograph shows the moon.">
<image mime-type="image/jpeg" src="CNX_Psych_02_04_moon.jpg"/>
</media>
<caption>Many people believe that a full moon makes people behave oddly. (credit: Cory Zanker)</caption> 
</figure>

<para id="fs-idm38381872">There is no denying that the moon exerts a powerful influence on our planet. The ebb and flow of the ocean’s tides are tightly tied to the gravitational forces of the moon. Many people believe, therefore, that it is logical that we are affected by the moon as well. After all, our bodies are largely made up of water. A meta-analysis of nearly 40 studies consistently demonstrated, however, that the relationship between the moon and our behavior does not exist (Rotton &amp; Kelly, 1985). While we may pay more attention to odd behavior during the full phase of the moon, the rates of odd behavior remain constant throughout the lunar cycle.</para>

<para id="fs-idm46730704">Why are we so apt to believe in illusory correlations like this? Often we read or hear about them and simply accept the information as valid. Or, we have a hunch about how something works and then look for evidence to support that hunch, ignoring evidence that would tell us our hunch is false; this is known as <term>confirmation bias</term>. Other times, we find illusory correlations based on the information that comes most easily to mind, even if that information is severely limited. And while we may feel confident that we can use these relationships to better understand and predict the world around us, illusory correlations can have significant drawbacks. For example, research suggests that illusory correlations—in which certain behaviors are inaccurately attributed to certain groups—are involved in the formation of prejudicial attitudes that can ultimately lead to discriminatory behavior (Fiedler, 2004).</para>
</section>
</section>

<section id="fs-idp9975072">
<title>CAUSALITY: CONDUCTING EXPERIMENTS AND USING THE DATA</title>
<para id="fs-idm22387104">As you’ve learned, the only way to establish that there is a cause-and-effect relationship between two variables is to conduct a scientific <term class="no-emphasis">experiment</term>. Experiment has a different meaning in the scientific context than in everyday life. In everyday conversation, we often use it to describe trying something for the first time, such as experimenting with a new hair style or a new food. However, in the scientific context, an experiment has precise requirements for design and implementation.</para><section id="fs-idm57740512">
<title>The Experimental Hypothesis</title>
<para id="fs-idm43016624">In order to conduct an experiment, a researcher must have a specific <term class="no-emphasis">hypothesis</term> to be tested. As you’ve learned, hypotheses can be formulated either through direct observation of the real world or after careful review of previous research. For example, if you think that children should not be allowed to watch violent programming on television because doing so would cause them to behave more violently, then you have basically formulated a hypothesis—namely, that watching violent television programs causes children to behave more violently. How might you have arrived at this particular hypothesis? You may have younger relatives who watch cartoons featuring characters using martial arts to save the world from evildoers, with an impressive array of punching, kicking, and defensive postures. You notice that after watching these programs for a while, your young relatives mimic the fighting behavior of the characters portrayed in the cartoon (<link target-id="CNX_Psych_02_05_toygun"/>).</para><figure id="CNX_Psych_02_05_toygun"><media id="fs-idm10182016" alt="A photograph shows a child pointing a toy gun.">
<image mime-type="image/jpeg" src="CNX_Psych_02_05_toygun.jpg"/>
</media>

<caption>Seeing behavior like this right after a child watches violent television programming might lead you to hypothesize that viewing violent television programming leads to an increase in the display of violent behaviors. (credit: Emran Kassim)</caption></figure><para id="fs-idp4153712">These sorts of personal observations are what often lead us to formulate a specific hypothesis, but we cannot use limited personal observations and anecdotal evidence to rigorously test our hypothesis. Instead, to find out if real-world data supports our hypothesis, we have to conduct an experiment.</para>
</section>

<section id="fs-idp3024240">
<title>Designing an Experiment</title>
<para id="fs-idp4610192">The most basic experimental design involves two groups: the experimental group and the control group. The two groups are designed to be the same except for one difference— experimental manipulation. The <term>experimental group</term> gets the experimental manipulation—that is, the treatment or variable being tested (in this case, violent TV images)—and the <term>control group</term> does not. Since experimental manipulation is the only difference between the experimental and control groups, we can be sure that any differences between the two are due to experimental manipulation rather than chance.</para>
<para id="fs-idm22193024">In our example of how violent television programming might affect violent behavior in children, we have the experimental group view violent television programming for a specified time and then measure their violent behavior. We measure the violent behavior in our control group after they watch nonviolent television programming for the same amount of time. It is important for the control group to be treated similarly to the experimental group, with the exception that the control group does not receive the experimental manipulation. Therefore, we have the control group watch non-violent television programming for the same amount of time as the experimental group.</para>
<para id="fs-idm22143056">We also need to precisely define, or operationalize, what is considered violent and nonviolent. An <term>operational definition</term> is a description of how we will measure our variables, and it is important in allowing others understand exactly how and what a researcher measures in a particular experiment. In operationalizing violent behavior, we might choose to count only physical acts like kicking or punching as instances of this behavior, or we also may choose to include angry verbal exchanges. Whatever we determine, it is important that we operationalize violent behavior in such a way that anyone who hears about our study for the first time knows exactly what we mean by violence. This aids peoples’ ability to interpret our data as well as their capacity to repeat our experiment should they choose to do so.</para>
<para id="fs-idm34133232">Once we have operationalized what is considered violent television programming and what is considered violent behavior from our experiment participants, we need to establish how we will run our experiment. In this case, we might have participants watch a 30-minute television program (either violent or nonviolent, depending on their group membership) before sending them out to a playground for an hour where their behavior is observed and the number and type of violent acts is recorded.</para>
<para id="fs-idm43450704">Ideally, the people who observe and record the children’s behavior are unaware of who was assigned to the experimental or control group, in order to control for experimenter bias. <term>Experimenter bias</term> refers to the possibility that a researcher’s expectations might skew the results of the study. Remember, conducting an experiment requires a lot of planning, and the people involved in the research project have a vested interest in supporting their hypotheses. If the observers knew which child was in which group, it might influence how much attention they paid to each child’s behavior as well as how they interpreted that behavior. By being blind to which child is in which group, we protect against those biases. This situation is a <term>single-blind study</term>, meaning that one of the groups (participants) are unaware as to which group they are in (experiment or control group) while the researcher who developed the experiment knows which participants are in each group.</para>
<para id="fs-idm30047504">In a <term>double-blind study</term>, both the researchers and the participants are blind to group assignments. Why would a researcher want to run a study where no one knows who is in which group? Because by doing so, we can control for both experimenter and participant expectations. If you are familiar with the phrase <term>placebo effect</term>, you already have some idea as to why this is an important consideration. The placebo effect occurs when people's expectations or beliefs influence or determine their experience in a given situation. In other words, simply expecting something to happen can actually make it happen.</para>
<para id="fs-idm31186832">The placebo effect is commonly described in terms of testing the effectiveness of a new medication. Imagine that you work in a pharmaceutical company, and you think you have a new drug that is effective in treating depression. To demonstrate that your medication is effective, you run an experiment with two groups: The experimental group receives the medication, and the control group does not. But you don’t want participants to know whether they received the drug or not.</para>
<para id="fs-idm15150144">Why is that? Imagine that you are a participant in this study, and you have just taken a pill that you think will improve your mood. Because you expect the pill to have an effect, you might feel better simply because you took the pill and not because of any drug actually contained in the pill—this is the placebo effect.</para>
<para id="fs-idm32705440">To make sure that any effects on mood are due to the drug and not due to expectations, the control group receives a placebo (in this case a sugar pill). Now everyone gets a pill, and once again neither the researcher nor the experimental participants know who got the drug and who got the sugar pill. Any differences in mood between the experimental and control groups can now be attributed to the drug itself rather than to experimenter bias or participant expectations (<link target-id="CNX_Psych_02_05_placebo"/>).</para>

<figure id="CNX_Psych_02_05_placebo">
<media id="fs-idp9324784" alt="A photograph shows three glass bottles of pills labeled as placebos.">
<image mime-type="image/jpeg" src="CNX_Psych_02_05_placebo.jpg"/>
</media>
<caption>Providing the control group with a placebo treatment protects against bias caused by expectancy. (credit: Elaine and Arthur Shapiro)</caption>
</figure>
</section>

<section id="fs-idm4342688">
<title>Independent and Dependent Variables</title>
<para id="fs-idp4642816">In a research experiment, we strive to study whether changes in one thing cause changes in another. To achieve this, we must pay attention to two important variables, or things that can be changed, in any experimental study: the independent variable and the dependent variable. An <term>independent variable</term> is manipulated or controlled by the experimenter. In a well-designed experimental study, the independent variable is the only important difference between the experimental and control groups. In our example of how violent television programs affect children’s display of violent behavior, the independent variable is the type of program—violent or nonviolent—viewed by participants in the study (<link target-id="CNX_Psych_02_05_variables"/>). A <term>dependent variable</term> is what the researcher measures to see how much effect the independent variable had. In our example, the dependent variable is the number of violent acts displayed by the experimental participants.</para>

<figure id="CNX_Psych_02_05_variables"><media id="fs-idm27054352" alt="A box labeled &#x201C;independent variable: type of television programming viewed&#x201D; contains a photograph of a person shooting an automatic weapon. An arrow labeled &#x201C;influences change in the&#x2026;&#x201D; leads to a second box. The second box is labeled &#x201C;dependent variable: violent behavior displayed&#x201D; and has a photograph of a child pointing a toy gun.">
<image mime-type="image/jpeg" src="CNX_Psych_02_05_variables.jpg"/>
</media>

<caption>In an experiment, manipulations of the independent variable are expected to result in changes in the dependent variable. (credit “automatic weapon”: modification of work by Daniel Oines; credit “toy gun”: modification of work by Emran Kassim)</caption></figure><para id="fs-idp44373456">We expect that the dependent variable will change as a function of the independent variable. In other words, the dependent variable <emphasis effect="italics">depends</emphasis> on the independent variable. A good way to think about the relationship between the independent and dependent variables is with this question: What effect does the independent variable have on the dependent variable? Returning to our example, what effect does watching a half hour of violent television programming or nonviolent television programming have on the number of incidents of physical aggression displayed on the playground?</para>
</section>

<section id="fs-idm13736208">
<title>Selecting and Assigning Experimental Participants</title>
<para id="fs-idm35111680">Now that our study is designed, we need to obtain a sample of individuals to include in our experiment. Our study involves human participants so we need to determine who to include. <term>Participants</term> are the subjects of psychological research, and as the name implies, individuals who are involved in psychological research actively participate in the process. Often, psychological research projects rely on college students to serve as participants. In fact, the vast majority of research in psychology subfields has historically involved students as research participants (Sears, 1986; Arnett, 2008). But are college students truly representative of the general population? College students tend to be younger, more educated, more liberal, and less diverse than the general population. Although using students as test subjects is an accepted practice, relying on such a limited pool of research participants can be problematic because it is difficult to generalize findings to the larger population.</para>
<para id="fs-idm53871616">Our hypothetical experiment involves children, and we must first generate a sample of child participants. Samples are used because populations are usually too large to reasonably involve every member in our particular experiment (<link target-id="CNX_Psych_02_05_sample"/>). If possible, we should use a random sample (there are other types of samples, but for the purposes of this chapter, we will focus on random samples). A <term>random sample</term> is a subset of a larger population in which every member of the population has an equal chance of being selected. Random samples are preferred because if the sample is large enough we can be reasonably sure that the participating individuals are representative of the larger population. This means that the percentages of characteristics in the sample—sex, ethnicity, socioeconomic level, and any other characteristics that might affect the results—are close to those percentages in the larger population.</para>
<para id="fs-idm59772960">In our example, let’s say we decide our population of interest is fourth graders. But all fourth graders is a very large population, so we need to be more specific; instead we might say our population of interest is all fourth graders in a particular city. We should include students from various income brackets, family situations, races, ethnicities, religions, and geographic areas of town. With this more manageable population, we can work with the local schools in selecting a random sample of around 200 fourth graders who we want to participate in our experiment.</para>
<para id="fs-idm43561728">In summary, because we cannot test all of the fourth graders in a city, we want to find a group of about 200 that reflects the composition of that city. With a representative group, we can generalize our findings to the larger population without fear of our sample being biased in some way.</para>

<figure id="CNX_Psych_02_05_sample"><media id="fs-idm26657312" alt="(a) A photograph shows an aerial view of crowds on a street. (b) A photograph shows s small group of children.">
<image mime-type="image/jpeg" src="CNX_Psych_02_05_sample.jpg"/>
</media>

<caption>Researchers may work with (a) a large population or (b) a sample group that is a subset of the larger population. (credit “crowd”: modification of work by James Cridland; credit “students”: modification of work by Laurie Sullivan)</caption></figure><para id="fs-idm58025968">Now that we have a sample, the next step of the experimental process is to split the participants into experimental and control groups through random assignment. With <term>random assignment</term>, all participants have an equal chance of being assigned to either group. There is statistical software that will randomly assign each of the fourth graders in the sample to either the experimental or the control group.</para>
<para id="fs-idm22541664">Random assignment is critical for sound <term class="no-emphasis">experimental design</term>. With sufficiently large samples, random assignment makes it unlikely that there are systematic differences between the groups. So, for instance, it would be very unlikely that we would get one group composed entirely of males, a given ethnic identity, or a given religious ideology. This is important because if the groups were systematically different before the experiment began, we would not know the origin of any differences we find between the groups: Were the differences preexisting, or were they caused by manipulation of the independent variable? Random assignment allows us to assume that any differences observed between experimental and control groups result from the manipulation of the independent variable.</para>

<note xmlns:data="http://www.w3.org/TR/html5/dom.html#custom-data-attribute" id="fs-idm46705312" class="psychology link-to-learning"><label>Link to Learning</label>

<media id="fs-idm8846640" alt=" ">
<image mime-type="png" src="OSC_Interactive_150.png"/>
</media>

<para id="fs-idm110380144">Use this <link url="https://www.randomizer.org/">online tool</link> to instantly generate randomized numbers and to learn more about random sampling and assignments.</para></note></section>

<section id="fs-idm26660352">
<title>Issues to Consider</title>
<para id="fs-idm84373440">While experiments allow scientists to make cause-and-effect claims, they are not without problems. True experiments require the experimenter to manipulate an independent variable, and that can complicate many questions that psychologists might want to address. For instance, imagine that you want to know what effect sex (the independent variable) has on spatial memory (the dependent variable). Although you can certainly look for differences between males and females on a task that taps into spatial memory, you cannot directly control a person’s sex. We categorize this type of research approach as quasi-experimental and recognize that we cannot make cause-and-effect claims in these circumstances.</para>
<para id="fs-idm110237888">Experimenters are also limited by ethical constraints. For instance, you would not be able to conduct an experiment designed to determine if experiencing abuse as a child leads to lower levels of self-esteem among adults. To conduct such an experiment, you would need to randomly assign some experimental participants to a group that receives abuse, and that experiment would be unethical.</para>
</section>

<section id="fs-idp16962688">
<title>Interpreting Experimental Findings</title>
<para id="fs-idp27164832">Once data is collected from both the experimental and the control groups, a <term>statistical analysis</term> is conducted to find out if there are meaningful differences between the two groups. A statistical analysis determines how likely any difference found is due to chance (and thus not meaningful). In psychology, group differences are considered meaningful, or significant, if the odds that these differences occurred by chance alone are 5 percent or less. Stated another way, if we repeated this experiment 100 times, we would expect to find the same results at least 95 times out of 100.</para>
<para id="fs-idm9623648">The greatest strength of experiments is the ability to assert that any significant differences in the findings are caused by the independent variable. This occurs because random selection, random assignment, and a design that limits the effects of both experimenter bias and participant expectancy should create groups that are similar in composition and treatment. Therefore, any difference between the groups is attributable to the independent variable, and now we can finally make a causal statement. If we find that watching a violent television program results in more violent behavior than watching a nonviolent program, we can safely say that watching violent television programs causes an increase in the display of violent behavior.</para>
</section>

<section id="fs-idm35834672">
<title>Reporting Research</title>
<para id="fs-idm40325120">When psychologists complete a research project, they generally want to share their findings with other scientists. The American Psychological Association (APA) publishes a manual detailing how to write a paper for submission to scientific journals. Unlike an article that might be published in a magazine like <emphasis effect="italics">Psychology Today, </emphasis>which targets a general audience with an interest in psychology, scientific journals generally publish <term>peer-reviewed journal articles</term> aimed at an audience of professionals and scholars who are actively involved in research themselves.</para>

<note id="fs-idm22108992" class="psychology link-to-learning"><label>Link to Learning</label>
<media id="fs-idm110355904" alt=" ">
<image mime-type="png" src="OSC_Interactive_150.png"/>
</media>

<para id="fs-idp23808">The <link url="http://openstaxcollege.org/l/owl">Online Writing Lab (OWL)</link> at Purdue University can walk you through the APA writing guidelines.</para>
</note><para id="fs-idm62557504">A peer-reviewed journal article is read by several other scientists (generally anonymously) with expertise in the subject matter. These peer reviewers provide feedback—to both the author and the journal editor—regarding the quality of the draft. Peer reviewers look for a strong rationale for the research being described, a clear description of how the research was conducted, and evidence that the research was conducted in an ethical manner. They also look for flaws in the study's design, methods, and statistical analyses. They check that the conclusions drawn by the authors seem reasonable given the observations made during the research. Peer reviewers also comment on how valuable the research is in advancing the discipline’s knowledge. This helps prevent unnecessary duplication of research findings in the scientific literature and, to some extent, ensures that each research article provides new information. Ultimately, the journal editor will compile all of the peer reviewer feedback and determine whether the article will be published in its current state (a rare occurrence), published with revisions, or not accepted for publication.</para>
<para id="fs-idm25798976">Peer review provides some degree of quality control for psychological research. Poorly conceived or executed studies can be weeded out, and even well-designed research can be improved by the revisions suggested. Peer review also ensures that the research is described clearly enough to allow other scientists to <term>replicate</term> it, meaning they can repeat the experiment using different samples to determine reliability. Sometimes replications involve additional measures that expand on the original finding. In any case, each replication serves to provide more evidence to support the original research findings. Successful replications of published research make scientists more apt to adopt those findings, while repeated failures tend to cast doubt on the legitimacy of the original article and lead scientists to look elsewhere. For example, it would be a major advancement in the medical field if a published study indicated that taking a new drug helped individuals achieve a healthy weight without changing their diet. But if other scientists could not replicate the results, the original study’s claims would be questioned.</para>

<note id="fs-idp8756544" class="psychology dig-deeper">
<label>Dig Deeper</label>
<title>The Vaccine-Autism Myth and Retraction of Published Studies</title>
<para id="fs-idm6414480">Some scientists have claimed that routine childhood vaccines cause some children to develop autism, and, in fact, several peer-reviewed publications published research making these claims. Since the initial reports, large-scale epidemiological research has suggested that vaccinations are not responsible for causing autism and that it is much safer to have your child vaccinated than not. Furthermore, several of the original studies making this claim have since been retracted.</para>
<para id="fs-idm28915072">A published piece of work can be rescinded when data is called into question because of falsification, fabrication, or serious research design problems. Once rescinded, the scientific community is informed that there are serious problems with the original publication. Retractions can be initiated by the researcher who led the study, by research collaborators, by the institution that employed the researcher, or by the editorial board of the journal in which the article was originally published. In the vaccine-autism case, the retraction was made because of a significant conflict of interest in which the leading researcher had a financial interest in establishing a link between childhood vaccines and autism (Offit, 2008). Unfortunately, the initial studies received so much media attention that many parents around the world became hesitant to have their children vaccinated (<link target-id="CNX_Psych_02_05_vaccine"/>). For more information about how the vaccine/autism story unfolded, as well as the repercussions of this story, take a look at Paul Offit’s book, <emphasis effect="italics">Autism’s False Prophets: Bad Science, Risky Medicine, and the Search for a Cure.</emphasis></para>

<figure id="CNX_Psych_02_05_vaccine"><media id="fs-idm40223280" alt="A photograph shows a child being given an oral vaccine.">
<image mime-type="image/jpeg" src="CNX_Psych_02_05_vaccine.jpg"/>
</media>

<caption>Some people still think vaccinations cause autism. (credit: modification of work by UNICEF Sverige)</caption></figure></note></section>
</section>

<section id="fs-idp8428288">
<title>RELIABILITY AND VALIDITY</title>
<para id="fs-idm12719232">Reliability and validity are two important considerations that must be made with any type of data collection. <term>Reliability</term> refers to the ability to consistently produce a given result. In the context of psychological research, this would mean that any instruments or tools used to collect data do so in consistent, reproducible ways.</para>
<para id="fs-idm47286192">Unfortunately, being consistent in measurement does not necessarily mean that you have measured something correctly. To illustrate this concept, consider a kitchen scale that would be used to measure the weight of cereal that you eat in the morning. If the scale is not properly calibrated, it may consistently under- or overestimate the amount of cereal that’s being measured. While the scale is highly reliable in producing consistent results (e.g., the same amount of cereal poured onto the scale produces the same reading each time), those results are incorrect. This is where validity comes into play. <term>Validity</term> refers to the extent to which a given instrument or tool accurately measures what it’s supposed to measure. While any valid measure is by necessity reliable, the reverse is not necessarily true. Researchers strive to use instruments that are both highly reliable and valid.</para>

<note id="fs-idm1746544" class="psychology everyday-connection"><label>Everyday Connection</label><title>How Valid Is the SAT?</title>

<para id="eip-idp14679856">
Standardized tests like the SAT are supposed to measure an individual’s aptitude for a college education, but how reliable and valid are such tests? Research conducted by the College Board suggests that scores on the SAT have high predictive validity for first-year college students’ GPA (Kobrin, Patterson, Shaw, Mattern, &amp; Barbuti, 2008). In this context, predictive validity refers to the test’s ability to effectively predict the GPA of college freshmen. Given that many institutions of higher education require the SAT for admission, this high degree of predictive validity might be comforting.</para>
<para id="fs-idp46777312">However, the emphasis placed on SAT scores in college admissions has generated some controversy on a number of fronts. For one, some researchers assert that the SAT is a biased test that places minority students at a disadvantage and unfairly reduces the likelihood of being admitted into a college (Santelices &amp; Wilson, 2010). Additionally, some research has suggested that the predictive validity of the SAT is grossly exaggerated in how well it is able to predict the GPA of first-year college students. In fact, it has been suggested that the SAT’s predictive validity may be overestimated by as much as 150% (Rothstein, 2004). Many institutions of higher education are beginning to consider de-emphasizing the significance of SAT scores in making admission decisions (Rimer, 2008).</para>
<para id="fs-idm62166896">In 2014, College Board president David Coleman expressed his awareness of these problems, recognizing that college success is more accurately predicted by high school grades than by SAT scores. To address these concerns, he has called for significant changes to the SAT exam (Lewin, 2014).</para>
</note></section>

<section id="fs-idm32424896" class="summary">
<title>Summary</title>
<para id="fs-idm50785152">A correlation is described with a correlation coefficient, <emphasis effect="italics">r</emphasis>, which ranges from -1 to 1. The correlation coefficient tells us about the nature (positive or negative) and the strength of the relationship between two or more variables. Correlations do not tell us anything about causation—regardless of how strong the relationship is between variables. In fact, the only way to demonstrate causation is by conducting an experiment. People often make the mistake of claiming that correlations exist when they really do not.</para>
<para id="fs-idm27914128">Researchers can test cause-and-effect hypotheses by conducting experiments. Ideally, experimental participants are randomly selected from the population of interest. Then, the participants are randomly assigned to their respective groups. Sometimes, the researcher and the participants are blind to group membership to prevent their expectations from influencing the results.</para>
<para id="fs-idm45123680">In ideal experimental design, the only difference between the experimental and control groups is whether participants are exposed to the experimental manipulation. Each group goes through all phases of the experiment, but each group will experience a different level of the independent variable: the experimental group is exposed to the experimental manipulation, and the control group is not exposed to the experimental manipulation. The researcher then measures the changes that are produced in the dependent variable in each group. Once data is collected from both groups, it is analyzed statistically to determine if there are meaningful differences between the groups.</para>
<para id="fs-idm28746832">Psychologists report their research findings in peer-reviewed journal articles. Research published in this format is checked by several other psychologists who serve as a filter separating ideas that are supported by evidence from ideas that are not. Replication has an important role in ensuring the legitimacy of published research. In the long run, only those findings that are capable of being replicated consistently will achieve consensus in the scientific community.</para> 
</section>

<section id="fs-idm48198288" class="review-questions">
<title>Review Questions</title>
<exercise id="fs-idm28997136">
<problem id="fs-idm37353344">
<para xmlns:data="http://www.w3.org/TR/html5/dom.html#custom-data-attribute" id="fs-idm49095696">Height and weight are positively correlated. This means that:</para><list xmlns:data="http://www.w3.org/TR/html5/dom.html#custom-data-attribute" id="fs-idm53151072" list-type="enumerated" number-style="lower-alpha"><item>There is no relationship between height and weight.  </item>
<item>Usually, the taller someone is, the thinner they are. </item>
<item>Usually, the shorter someone is, the heavier they are.</item>
<item>As height increases, typically weight increases.</item>
</list></problem>
<solution id="fs-idm51992960">
<para id="fs-idm22603936">D</para>
</solution>
</exercise>
<exercise id="fs-idm46475056">
<problem id="fs-idm56979680">
<para id="fs-idm37895040">Which of the following correlation coefficients indicates the strongest relationship between two variables?</para>
<list id="fs-idm36786336" list-type="enumerated" number-style="lower-alpha"><item>-.90</item>
<item>-.50</item>
<item>+.80</item>
<item>+.25</item>
</list></problem>
<solution id="fs-idm46921600">
<para id="fs-idm28174240">A</para>
</solution>
</exercise>
<exercise id="fs-idp2894320">
<problem id="fs-idm36225840">
<para id="fs-idm43046048">Which statement best illustrates a negative correlation between the number of hours spent watching TV the week before an exam and the grade on that exam?</para>
<list id="fs-idm37291520" list-type="enumerated" number-style="lower-alpha"><item>Watching too much television leads to poor exam performance.</item>
<item>Smart students watch less television.</item>
<item>Viewing television interferes with a student’s ability to prepare for the upcoming exam.</item>
<item>Students who watch more television perform more poorly on their exams.</item>
</list></problem>
<solution id="fs-idm60764272">
<para id="fs-idm55425456">D</para>
</solution>
</exercise>
<exercise id="fs-idm32547936">
<problem id="fs-idm112180016">
<para id="fs-idm62937136">The correlation coefficient indicates the weakest relationship when ________.</para>
<list id="fs-idm104437632" list-type="enumerated" number-style="lower-alpha"><item>it is closest to 0</item>
<item>it is closest to -1</item>
<item>it is positive</item> 
<item>it is negative</item> 
</list></problem>
<solution id="fs-idp8813568">
<para xmlns:data="http://www.w3.org/TR/html5/dom.html#custom-data-attribute" id="fs-idm48148976">A</para></solution>
</exercise>
<exercise id="fs-idm46864688">
<problem id="fs-idm26285920">
<para id="fs-idm59818768">________ means that everyone in the population has the same likelihood of being asked to participate in the study.</para>
<list id="fs-idm51910016" list-type="enumerated" number-style="lower-alpha"><item>operationalizing</item>
<item>placebo effect</item>
<item>random assignment</item>
<item>random sampling</item>
</list></problem>
<solution id="fs-idm54033984">
<para id="fs-idm48018336">D</para>
</solution>
</exercise>
<exercise id="fs-idm44434400">
<problem id="fs-idp1493984">
<para id="fs-idm38226848">The ________ is controlled by the experimenter, while the ________ represents the information collected and statistically analyzed by the experimenter.</para>
<list id="fs-idm27085184" list-type="enumerated" number-style="lower-alpha"><item>dependent variable; independent variable</item>
<item>independent variable; dependent variable</item>
<item>placebo effect; experimenter bias</item>
<item>experiment bias; placebo effect</item>
</list></problem>
<solution id="fs-idm49016592"><para id="fs-idm27362128">B</para></solution>
</exercise>
<exercise id="fs-idm38751904">
<problem id="fs-idm29513520">
<para id="fs-idm44835632">Researchers must ________ important concepts in their studies so others would have a clear understanding of exactly how those concepts were defined.</para>
<list id="fs-idm10166800" list-type="enumerated" number-style="lower-alpha"><item>randomly assign</item>
<item>randomly select</item>
<item>operationalize</item>
<item>generalize</item>
</list></problem>
<solution id="fs-idm37830256"><para id="fs-idm46887600">C</para></solution>
</exercise>
<exercise id="fs-idm38758640"><problem id="fs-idm44673504">
<para id="fs-idm22257664">Sometimes, researchers will administer a(n) ________ to participants in the control group to control for the effects that participant expectation might have on the experiment.</para>
<list id="fs-idp9148176" list-type="enumerated" number-style="lower-alpha"><item>dependent variable</item>
<item>independent variable</item>
<item>statistical analysis</item>
<item>placebo</item>
</list></problem>
<solution id="eip-idp3728800">
<para id="eip-idp9628112">D</para>
</solution>
</exercise>
</section>

<section id="fs-idm32641712" class="critical-thinking">
<title>Critical Thinking Questions</title>
<exercise id="fs-idm37308480">
<problem id="fs-idm89625680"><para id="fs-idm26674768">Earlier in this section, we read about research suggesting that there is a correlation between eating cereal and weight. Cereal companies that present this information in their advertisements could lead someone to believe that eating more cereal causes healthy weight. Why would they make such a claim and what arguments could you make to counter this cause-and-effect claim?</para></problem>
<solution id="fs-idp44423440"><para id="fs-idm91768432">The cereal companies are trying to make a profit, so framing the research findings in this way would improve their bottom line. However, it could be that people who forgo more fatty options for breakfast are health conscious and engage in a variety of other behaviors that help them maintain a healthy weight.</para></solution>
</exercise>
<exercise id="fs-idp4287136">
<problem id="fs-idp4287392"><para id="fs-idp4287520">Recently a study was published in the journal, <emphasis effect="italics">Nutrition and Cancer</emphasis>, which established a negative correlation between coffee consumption and breast cancer. Specifically, it was found that women consuming more than 5 cups of coffee a day were less likely to develop breast cancer than women who never consumed coffee (Lowcock, Cotterchio, Anderson, Boucher, &amp; El-Sohemy, 2013). Imagine you see a newspaper story about this research that says, “Coffee Protects Against Cancer.” Why is this headline misleading and why would a more accurate headline draw less interest?</para></problem>
<solution id="fs-idm29229328"><para id="fs-idm22289328">Using the word protects seems to suggest causation as a function of correlation. If the headline were more accurate, it would be less interesting because indicating that two things are associated is less powerful than indicating that doing one thing causes a change in the other.</para></solution>
</exercise>
<exercise id="fs-idp4002784">
<problem id="fs-idm40432128"><para id="fs-idm30082304">Sometimes, true random sampling can be very difficult to obtain. Many researchers make use of convenience samples as an alternative. For example, one popular convenience sample would involve students enrolled in Introduction to Psychology courses. What are the implications of using this sampling technique?</para></problem>
<solution id="fs-idm30971232"><para id="fs-idm30971104">If research is limited to students enrolled in Introduction to Psychology courses, then our ability to generalize to the larger population would be dramatically reduced. One could also argue that students enrolled in Introduction to Psychology courses may not be representative of the larger population of college students at their school, much less the larger general population.</para></solution>
</exercise>
<exercise id="fs-idm30970192"><problem id="fs-idm30970064"><para id="fs-idm30969936">Peer review is an important part of publishing research findings in many scientific disciplines. This process is normally conducted anonymously; in other words, the author of the article being reviewed does not know who is reviewing the article, and the reviewers are unaware of the author’s identity. Why would this be an important part of this process?</para></problem>
<solution id="fs-idm66774848"><para id="fs-idp2853792">Anonymity protects against personal biases interfering with the reviewer’s opinion of the research. Allowing the reviewer to remain anonymous would mean that they can be honest in their appraisal of the manuscript without fear of reprisal.</para></solution>
</exercise>
</section>

<section id="fs-idm25426608" class="personal-application">
<title>Personal Application Questions</title>
<exercise id="fs-idm44686896"><problem id="fs-idm29010832"><para id="fs-idm89559856">We all have a tendency to make illusory correlations from time to time. Try to think of an illusory correlation that is held by you, a family member, or a close friend. How do you think this illusory correlation came about and what can be done in the future to combat them?</para></problem></exercise>
<exercise id="fs-idm46356816"><problem id="fs-idm50743360"><para id="fs-idp4715008">Are there any questions about human or animal behavior that you would really like to answer? Generate a hypothesis and briefly describe how you would conduct an experiment to answer your question.</para></problem></exercise>
</section>



</content>
<glossary>
<definition id="fs-idm46583680">
<term>cause-and-effect relationship</term>
<meaning id="fs-idm26218336">changes in one variable cause the changes in the other variable; can be determined only through an experimental research design</meaning>
</definition>
<definition id="fs-idm32265248">
<term>confirmation bias</term> 
<meaning id="fs-idm73161824">tendency to ignore evidence that disproves ideas or beliefs</meaning>
</definition>

<definition id="fs-idm56194640">
<term>confounding variable</term> 
<meaning id="fs-idm54758496">unanticipated outside factor that affects both variables of interest, often giving the false impression that changes in one variable causes changes in the other variable, when, in actuality, the outside factor causes changes in both variables</meaning>
</definition>


<definition id="fs-idm22328736">
<term>control group</term> 
<meaning id="fs-idm21393648">serves as a basis for comparison and controls for chance factors that might influence the results of the study—by holding such factors constant across groups so that the experimental manipulation is the only difference between groups
</meaning>
</definition>


<definition id="fs-idm28722304">
<term>correlation</term> 
<meaning id="fs-idm12252928">relationship between two or more variables; when two variables are correlated, one variable changes as the other does</meaning>
</definition>


<definition id="fs-idp44393280">
<term>correlation coefficient</term> 
<meaning id="fs-idp44393952">number from -1 to +1, indicating the strength and direction of the relationship between variables, and usually represented by <emphasis effect="italics">r</emphasis></meaning>
</definition>





<definition id="fs-idm13693024">
<term>dependent variable</term> 
<meaning id="fs-idm78518352">variable that the researcher measures to see how much effect the independent variable had</meaning>
</definition>
<definition id="fs-idm37316960">
<term>double-blind study</term> 
<meaning id="fs-idm59903648">experiment in which both the researchers and the participants are blind to group assignments</meaning>
</definition>

<definition id="fs-idm35369168">
<term>experimental group</term> 
<meaning id="fs-idm52655728">group designed to answer the research question; experimental manipulation is the only difference between the experimental and control groups, so any differences between the two are due to experimental manipulation rather than chance</meaning>
</definition>
<definition id="fs-idm30846656">
<term>experimenter bias</term>
<meaning id="fs-idm28861360">researcher expectations skew the results of the study</meaning>
</definition>
<definition id="fs-idp9492560">
<term>illusory correlation</term> 
<meaning id="fs-idm46561872">seeing relationships between two things when in reality no such relationship exists</meaning>
</definition>
<definition id="fs-idm6476000">
<term>independent variable</term> 
<meaning id="fs-idm29021152">variable that is influenced or controlled by the experimenter; in a sound experimental study, the independent variable is the only important difference between the experimental and control group</meaning>
</definition>
<definition id="fs-idm30993536">
<term>negative correlation</term>
<meaning id="fs-idm47297216">two variables change in different directions, with one becoming larger as the other becomes smaller; a negative correlation is not the same thing as no correlation</meaning>
</definition>
<definition id="fs-idm29055856">
<term>operational definition</term> 
<meaning id="fs-idm54957824">description of what actions and operations will be used to measure the dependent variables and manipulate the independent variables</meaning>
</definition>
<definition id="fs-idm62295504">
<term>participants</term> 
<meaning id="fs-idp28449920">subjects of psychological research</meaning>
</definition>
<definition id="fs-idp4616752">
<term>peer-reviewed journal article</term>
<meaning id="fs-idm32744992">article read by several other scientists (usually anonymously) with expertise in the subject matter, who provide feedback regarding the quality of the manuscript before it is accepted for publication</meaning>
</definition>
<definition id="fs-idm46590416">
<term>placebo effect</term>
<meaning id="fs-idm59439824">people's expectations or beliefs influencing or determining their experience in a given situation</meaning>
</definition>
<definition id="fs-idm36014112">
<term>positive correlation</term>
<meaning id="fs-idp2475856">two variables change in the same direction, both becoming either larger or smaller</meaning>
</definition>
<definition id="fs-idm48289680">
<term>random assignment</term> 
<meaning id="fs-idm47999552">method of experimental group assignment in which all participants have an equal chance of being assigned to either group</meaning>
</definition>
<definition id="fs-idm10170928">
<term>random sample</term> 
<meaning id="fs-idp3107552">subset of a larger population in which every member of the population has an equal chance of being selected</meaning>
</definition>
<definition id="fs-idm33636816">
<term>reliability</term> 
<meaning id="fs-idm62968512">consistency and reproducibility of a given result</meaning>
</definition>
<definition id="fs-idm35869632">
<term>replicate</term> 
<meaning id="fs-idm60378384">repeating an experiment using different samples to determine the research’s reliability</meaning>
</definition>
<definition id="fs-idm62308720">
<term>single-blind study</term> 
<meaning id="fs-idm20457792">experiment in which the researcher knows which participants are in the experimental group and which are in the control group</meaning>
</definition>
<definition id="fs-idm37270320">
<term>statistical analysis</term> 
<meaning id="fs-idm47823408">determines how likely any difference between experimental groups is due to chance</meaning>
</definition>
<definition id="fs-idm62078640">
<term>validity</term> 
<meaning id="fs-idm63943216">accuracy of a given result in measuring what it is designed to measure</meaning>
</definition>
</glossary>
</document>
